properties([
	disableConcurrentBuilds(),
	disableResume(),
	durabilityHint('PERFORMANCE_OPTIMIZED'),
	pipelineTriggers([
		githubPush(),
		cron('@hourly'), // check periodically to bring in new image builds
	]),
])

node('doi-meta') { // use the dedicated meta instance
	stage('Checkout') {
		// prevent meta from triggering itself
		// If 'Include in polling' is enabled or 'Include in changelog' is enabled, then when polling occurs, the job will be started if changes are detected from this SCM source.
		checkout(changelog: false, poll: false, scm: scmGit(
			userRemoteConfigs: [[
				url: 'git@github.com:docker-library/meta.git',
				credentialsId: 'docker-library-bot',
				name: 'origin',
			]],
			branches: [[name: '*/main']],
			extensions: [
				cloneOption(
					noTags: true,
					shallow: true,
					depth: 1,
				),
				submodule(
					parentCredentials: true,
					recursiveSubmodules: true,
					trackingSubmodules: true,
				),
				cleanBeforeCheckout(),
				cleanAfterCheckout(),
				[$class: 'RelativeTargetDirectory', relativeTargetDir: 'meta'],
			],
		))
		checkout(scmGit(
			userRemoteConfigs: [[
				url: 'https://github.com/docker-library/official-images.git',
				name: 'origin',
			]],
			branches: [[name: '*/master']],
			extensions: [
				cleanBeforeCheckout(),
				cleanAfterCheckout(),
				[$class: 'RelativeTargetDirectory', relativeTargetDir: 'meta/.doi'],
			],
		))
		checkout(scmGit(
			userRemoteConfigs: [[
				url: 'https://github.com/docker-library/meta-scripts.git',
				name: 'origin',
			]],
			branches: [[name: '*/main']],
			extensions: [
				cleanBeforeCheckout(),
				cleanAfterCheckout(),
				[$class: 'RelativeTargetDirectory', relativeTargetDir: 'meta/.scripts'],
			],
		))
		sh '''
			git -C meta config user.name 'Docker Library Bot'
			git -C meta config user.email 'doi+docker-library-bot@docker.com'
		'''
	}

	env.BASHBREW_LIBRARY = workspace + '/meta/.doi/library'

	dir('meta') {
		withCredentials([
			// thanks to rate limits, we either have to "docker login" or look things up via our proxy
			string(credentialsId: 'dockerhub-public-proxy', variable: 'DOCKERHUB_PUBLIC_PROXY'),
		]) {
			stage('Fetch') {
				sh 'bashbrew --library .doi/library fetch --all'
			}
			stage('Sources') {
				sh '''
					# we only need to regenerate "sources.json" if ".doi" or ".scripts" have changed since we last generated it

					needsBuild=
					if [ ! -s commits.json ] || [ ! -s sources.json ]; then
						needsBuild=1
					fi

					doi="$(git -C .doi log -1 --format='format:%H')"
					scripts="$(git -C .scripts log -1 --format='format:%H')"
					export doi scripts
					jq -n '{ doi: env.doi, scripts: env.scripts }' | tee commits.json
					if [ -z "$needsBuild" ] && ! git diff --exit-code commits.json; then
						needsBuild=1
					fi

					if [ -n "$needsBuild" ]; then
						# use previous run as cache
						[ -s sources.json ] && cp sources.json sources-copy.json

						.scripts/sources.sh --cache-file sources-copy.json --all > sources.json

						# clean up temporary cache
						rm -f sources-copy.json
					fi
				'''
			}
			stage('Builds') {
				sh '.scripts/builds.sh --cache cache-builds.json sources.json > builds.json'
			}
		}
		stage('Janky') {
			// ideally, the other jobs that act on the data generated by this one would directly reference each Jenkinsfile.* from *within* the ".scripts" submodule that this job has updated (so that we only run updated scripts with updated data, in the case of something major changing for example)
			// Jenkins *does* technically support this, but it requires disabling "lightweight checkout", and doing the full checkout of "meta" (even just making sure it's up-to-date) *just* to grab a single Jenkinsfile from the .scripts submodule is really heavy and kicks over our Jenkins server
			// to mitigate this, we "copy up" the Jenkinsfiles directly into "meta" so that we can go back to a "lightweight" checkout
			sh '''
				rm -rf .jenkins
				mkdir .jenkins
				echo 'Jenkinsfile*  linguist-language=groovy' > .jenkins/.gitattributes
				cp -av .scripts/Jenkinsfile* .jenkins/
			'''
		}
		stage('Commit') {
			sh '''
				git add -A .
				if ! git diff --staged --exit-code; then # commit fails if there's nothing to commit
					git commit -m 'Update and regenerate'
				fi
			'''
		}
		sshagent(['docker-library-bot']) {
			stage('Push') {
				sh 'git push origin HEAD:main'
			}
		}
	}
}
